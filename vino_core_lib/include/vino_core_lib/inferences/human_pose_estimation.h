// TODO add license

/**
 * @brief A header file with declaration for AgeGenderDetection Class
 * @file human_pose_estimation.h
 */
#ifndef VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H
#define VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H

#include <memory>
#include <string>
#include <vector>

#include "vino_core_lib/engines/engine.h"
#include "vino_core_lib/inferences/base_inference.h"
#include "vino_core_lib/models/human_pose_estimation_model.h"
#include "inference_engine.hpp"
#include "opencv2/opencv.hpp"

namespace vino_core_lib
{

/**
 * @class HumanPoseResult
 * @brief Class for storing and processing age and gender detection result.
 */
class HumanPoseResult : public Result
{
 public:
  explicit HumanPoseResult(const cv::Rect& location);
  HumanPoseResult(
    const cv::Rect& location,
    const std::vector<cv::Point2f>& keypoints, // = std::vector<cv::Point2f>(),
    const float& score); // = 0);
  
  // Following similar structure of vino_core_lib/inferences/object_detection.h
  // and human_pose_estimation_demo/src/human_pose_estimator.h

  /**
   * @brief Get the age keypoints of the estimated pose from the result.
   * @return The estimated keypoints.
   */
  std::vector<cv::Point2f> getKeypoints() const
  {
    return keypoints;
  }

  /**
   * @brief Get the score of the estimated pose from the result.
   * @return The score of the estimation.
   */
  float getScore() const
  {
    return score;
  }

  std::vector<cv::Point2f> keypoints;
  float score = -1;
};


/**
 * @class HumanPoseEstimation
 * @brief Class to load the human pose estimation model and perform
   human pose estimation.
 */
class HumanPoseEstimation : public BaseInference
{
 public:
  using Result = vino_core_lib::HumanPoseResult;
  HumanPoseEstimation(float minPeaksDistance,
                      float midPointsScoreThreshold,
                      float foundMidPointsRatioThreshold,
                      int minJointsNumber,
                      float minSubsetScore);
  ~HumanPoseEstimation() override;
  /**
   * @brief Load the age gender detection model.
   */
  void loadNetwork(std::shared_ptr<Models::HumanPoseEstimationModel>);
  /**
   * @brief Enqueue a frame to this class.
   * The frame will be buffered but not inferred yet.
   * @param[in] frame The frame to be enqueued.
   * @param[in] input_frame_loc The location of the enqueued frame with respect
   * to the frame generated by the input device.
   * @return Whether this operation is successful.
   */
  bool enqueue(const cv::Mat& frame, const cv::Rect&) override;
  /**
   * @brief Start inference for all buffered frames.
   * @return Whether this operation is successful.
   */
  bool submitRequest() override;
  /**
   * @brief This function will fetch the results of the previous inference and
   * stores the results in a result buffer array. All buffered frames will be
   * cleared.
   * @return Whether the Inference object fetches a result this time
   */
  bool fetchResults() override;
  /**
   * @brief Get the length of the buffer result array.
   * @return The length of the buffer result array.
   */
  const int getResultsLength() const override;
  /**
   * @brief Get the location of result with respect
   * to the frame generated by the input device.
   * @param[in] idx The index of the result.
   */
  const vino_core_lib::Result* getLocationResult(int idx) const override;
  /**
   * @brief Get the name of the Inference instance.
   * @return The name of the Inference instance.
   */
  const std::string getName() const override;
  /**
   * @brief Show the observed detection result either through image window
   * or ROS topic.
   */
  const void observeOutput(
      const std::shared_ptr<Outputs::BaseOutput>& output) override;

 private:
  /**
   * @brief Processess the network's outputs to extract the valid poses.
   * 
   * Copied from: https://github.com/opencv/open_model_zoo/blob/master/demos/human_pose_estimation_demo/src/human_pose_estimator.cpp
   * 
   * @param heatMapsData Data outputted by the heatmap network.
   * @param heatMapOffset Size of each heatmap result.
   * @param nHeatMaps Number of keypoints.
   * @param pafsData Data outputted by the PAF network.
   * @param pafOffset Size of each PAF result.
   * @param nPafs Numver of PAFs.
   * @param featureMapWidth Width of the heatmap.
   * @param featureMapHeight Height of the heatmap.
   * @param imageSize Size of the input image.
   * @return std::vector<Result> A vector with the detected poses.
   */
  std::vector<Result> postprocess(
            const float* heatMapsData, const int heatMapOffset, const int nHeatMaps,
            const float* pafsData, const int pafOffset, const int nPafs,
            const int featureMapWidth, const int featureMapHeight,
            const cv::Size& imageSize) const;
  
  /**
   * @brief Resizes the heatmap by upSampleRatio.
   * 
   * @param featureMaps A vector with the heatmaps to resize.
   */
  void resizeFeatureMaps(std::vector<cv::Mat>& featureMaps) const;

  /**
   * @brief Extracts the poses from the given heatmaps and PAFs.
   * 
   * @param heatMaps Postprocessed heatmaps.
   * @param pafs Postprocessed PAFs.
   * @return std::vector<Result> The detected poses.
   */
  std::vector<Result> extractPoses(
        const std::vector<cv::Mat>& heatMaps,
        const std::vector<cv::Mat>& pafs) const;

  /**
   * @brief Aligns the poses' keypoints to the input image.
   * 
   * @param poses Poses (extracted from the heatmaps and PAFs).
   * @param featureMapsSize  The size of the heatmaps.
   * @param imageSize The input image size.
   */
  void correctCoordinates(std::vector<Result>& poses,
                          const cv::Size& featureMapsSize,
                          const cv::Size& imageSize) const;
  
  /**
   * @brief Correct the bonding boxes based on the poses' keypoints.
   * 
   * @param poses Poses (with corrected keypoints).
   */
  void correctROI(std::vector<Result>& poses) const;

  std::shared_ptr<Models::HumanPoseEstimationModel> valid_model_;
  std::vector<Result> results_;
  int width_ = 0;
  int height_ = 0;

  const size_t keypointsNumber_ = 18;
  int upsampleRatio_;
  float minPeaksDistance_;
  float midPointsScoreThreshold_;
  float foundMidPointsRatioThreshold_;
  int minJointsNumber_;
  float minSubsetScore_;
  int stride_;
  cv::Vec4i pad_;
};

} //  namespace vino_core_lib

#endif  // VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H