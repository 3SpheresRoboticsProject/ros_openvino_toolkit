// TODO add license

/**
 * @brief A header file with declaration for AgeGenderDetection Class
 * @file human_pose_estimation.h
 */
#ifndef VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H
#define VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H

#include <memory>
#include <string>
#include <vector>

#include "vino_core_lib/engines/engine.h"
#include "vino_core_lib/inferences/base_inference.h"
#include "vino_core_lib/models/human_pose_estimation_model.h"
#include "inference_engine.hpp"
#include "opencv2/opencv.hpp"

namespace vino_core_lib
{

/**
 * @class HumanPoseResult
 * @brief Class for storing and processing age and gender detection result.
 */
class HumanPoseResult : public Result
{
 public:
  explicit HumanPoseResult(const cv::Rect& location);
  HumanPoseResult(
    const cv::Rect& location,
    const std::vector<cv::Point2f>& keypoints, // = std::vector<cv::Point2f>(),
    const float& score); // = 0);
  
  // Following similar structure of vino_core_lib/inferences/object_detection.h
  // and human_pose_estimation_demo/src/human_pose_estimator.h

  /**
   * @brief Get the age keypoints of the estimated pose from the result.
   * @return The estimated keypoints.
   */
  std::vector<cv::Point2f> getKeypoints() const
  {
    return keypoints;
  }

  /**
   * @brief Get the score of the estimated pose from the result.
   * @return The score of the estimation.
   */
  float getScore() const
  {
    return score;
  }

  std::vector<cv::Point2f> keypoints;
  float score = -1;
};


/**
 * @class HumanPoseEstimation
 * @brief Class to load the human pose estimation model and perform
   human pose estimation.
 */
class HumanPoseEstimation : public BaseInference
{
 public:
  using Result = vino_core_lib::HumanPoseResult;
  HumanPoseEstimation();
  ~HumanPoseEstimation() override;
  /**
   * @brief Load the age gender detection model.
   */
  void loadNetwork(std::shared_ptr<Models::HumanPoseEstimationModel>);
  /**
   * @brief Enqueue a frame to this class.
   * The frame will be buffered but not inferred yet.
   * @param[in] frame The frame to be enqueued.
   * @param[in] input_frame_loc The location of the enqueued frame with respect
   * to the frame generated by the input device.
   * @return Whether this operation is successful.
   */
  bool enqueue(const cv::Mat& frame, const cv::Rect&) override;
  /**
   * @brief Start inference for all buffered frames.
   * @return Whether this operation is successful.
   */
  bool submitRequest() override;
  /**
   * @brief This function will fetch the results of the previous inference and
   * stores the results in a result buffer array. All buffered frames will be
   * cleared.
   * @return Whether the Inference object fetches a result this time
   */
  bool fetchResults() override;
  /**
   * @brief Get the length of the buffer result array.
   * @return The length of the buffer result array.
   */
  const int getResultsLength() const override;
  /**
   * @brief Get the location of result with respect
   * to the frame generated by the input device.
   * @param[in] idx The index of the result.
   */
  const vino_core_lib::Result* getLocationResult(int idx) const override;
  /**
   * @brief Get the name of the Inference instance.
   * @return The name of the Inference instance.
   */
  const std::string getName() const override;
  /**
   * @brief Show the observed detection result either through image window
   * or ROS topic.
   */
  const void observeOutput(
      const std::shared_ptr<Outputs::BaseOutput>& output) override;

 private:
  /**
   * @brief 
   * 
   * Copied from: https://github.com/opencv/open_model_zoo/blob/master/demos/human_pose_estimation_demo/src/human_pose_estimator.cpp
   * 
   * @param heatMapsData 
   * @param heatMapOffset 
   * @param nHeatMaps 
   * @param pafsData 
   * @param pafOffset 
   * @param nPafs 
   * @param featureMapWidth 
   * @param featureMapHeight 
   * @param imageSize 
   * @return std::vector<Result> 
   */
  std::vector<Result> postprocess(
            const float* heatMapsData, const int heatMapOffset, const int nHeatMaps,
            const float* pafsData, const int pafOffset, const int nPafs,
            const int featureMapWidth, const int featureMapHeight,
            const cv::Size& imageSize) const;
  
  void resizeFeatureMaps(std::vector<cv::Mat>& featureMaps) const;

  std::vector<Result> extractPoses(
        const std::vector<cv::Mat>& heatMaps,
        const std::vector<cv::Mat>& pafs) const;

  void correctCoordinates(std::vector<Result>& poses,
                          const cv::Size& featureMapsSize,
                          const cv::Size& imageSize) const;
  
  void correctROI(std::vector<Result>& poses) const;

  std::shared_ptr<Models::HumanPoseEstimationModel> valid_model_;
  std::vector<Result> results_;
  int width_ = 0;
  int height_ = 0;

  // TODO add doc
  int upsampleRatio_; // = 4;
  float minPeaksDistance_; // = 3.0f;
  const size_t keypointsNumber_ = 18;
  float midPointsScoreThreshold_; // = 0.05f;
  float foundMidPointsRatioThreshold_; // = 0.8f;
  int minJointsNumber_; // = 3;
  float minSubsetScore_; // = 0.2f;
  int stride_; // = 8;
  cv::Vec4i pad_;
  cv::Size imageSize_; // = image.size();
};

} //  namespace vino_core_lib

#endif  // VINO_CORE_LIB_INFERENCES_HUMAN_POSE_ESTIMATION_H